# Lessons: aivp-ideation

## 实测教训（2026-02-22）

### 教训 1: AI 能力评估是选题基石
**错误**：跳过 AI 当前能力调研，用 3 个月前的过时认知（"角色一致性是 AI 短板"）做选题判断，导致错误排除了微短剧方向。实际上 Seedance 2.0/Kling 3.0 已解决角色一致性。

**修复**：增加 Layer 0（AI Capability Baseline），必须在 Round 1 首先执行。输出能力矩阵 → 分为 Green/Yellow/Red zone → 直接约束选题评分。

**原则**：AI 领域任何超过 3 个月的能力判断都不可信，必须重新验证。

### 教训 2: 问题必须带决策辅助信息
**错误**：先是把所有决策甩给用户（"英文还是中文？长视频还是 Shorts？"），后来又全替用户决定。两个极端都不对。

**修复**：定义 Decision Point Format——每个需要用户决定的问题必须包含：选项列表 + 每个选项的利弊 + 数据支撑 + 推荐。用户做的是"有依据的选择"，不是盲选。

**原则**：问题 = 选项 + 数据 + 推荐。永远不问裸问题。

### 教训 3: 信息时效性必须分类对待
**错误**：把不同保质期的信息混在一起，没有标注数据日期，导致过时信息污染决策。

**修复**：4 级保质期分类：
- AI 模型能力：1-3 个月（搜索必须加当前月份）
- 平台政策：3-6 个月
- 市场趋势：6-12 个月
- 人性/心理学：不过期

**原则**：研究数据必须标注来源日期。高时效信息（AI 能力）必须用最近 30 天的数据。

### 教训 4: 评分体系的维度要反映真实约束
**错误**：原来的"Producibility"维度只是模糊的 1-5 分，没有和 AI 能力矩阵挂钩。

**修复**：改为"AI Feasibility"，直接由 Layer 0 的 Green/Yellow/Red 分类决定。增加"Monetization Safety"维度（15%），因为变现政策是 AI 视频的硬约束。

### 教训 5: Skill 的交互流程必须实测验证
**错误**：写完 SKILL.md 就以为完成了。实测暴露了流程设计中的结构性缺陷（跳步、裸问题、缺少基石层）。

**原则**：每个 skill 必须完整跑一轮实测，用真实场景暴露设计问题，然后迭代。

## 版本记录
- v0.2.0: 初始版本（纯模板，curl 脚本）
- v0.3.0: 转为 agent 原生研究，修复脚本
- v0.4.0: 增加 Layer 0、Decision Point Format、Freshness Rules（本轮修复）
