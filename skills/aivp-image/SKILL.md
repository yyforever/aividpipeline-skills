---
name: aivp-image
description: Generate keyframe images for video production â€” character portraits, scene keyframes, and style frames via OpenRouter API. Activate on "generate keyframe", "create image", "character portrait", "scene image", "generate frames", or any image generation request in the video pipeline.
metadata:
  author: aividpipeline
  version: "0.3.0"
  tags: image, keyframe, openrouter, text-to-image, image-to-image, character-consistency
---

# AIVP Image â€” Keyframe Generation for Video Pipeline

Generate keyframe images that feed into aivp-video. Supports two modes:

1. **Pipeline mode** â€” read storyboard's frame-plan, generate all keyframes in Camera Tree order
2. **Standalone mode** â€” generate individual images from a text prompt

Default API: **OpenRouter** (`https://openrouter.ai/api/v1`). Model passed as parameter â€” not hardcoded.

## Core Process

```
Read storyboard outputs (frame-plan.md + shots/*.md)
     â†“
 For each frame in generation order:
     â”œâ”€ Build prompt (from shot spec + character/scene refs)
     â”œâ”€ Call generate.sh (OpenRouter API)
     â”œâ”€ Save image to image/frames/
     â”œâ”€ Log metadata to image/log/
     â””â”€ Update preview.md placeholder â†’ real image path
     â†“
 All frames generated â†’ quality review â†’ done
```

## Workflow

### Setup

1. **Locate API key** â€” Check these in order:
   - `OPENROUTER_API_KEY` environment variable
   - `.env` file in project root, `~/.env`, or `~/.aivp/.env`
2. **Read storyboard outputs** (pipeline mode):
   - `storyboard/storyboard-final/frame-plan.md` â€” generation order + reference image list
   - `storyboard/storyboard-final/shots/shot-{NN}.md` â€” per-shot specs (prompt, resolution, references)
   - `script/characters/*.md` â€” character portrait descriptions (text)
   - `script/scenes/*.md` â€” scene background descriptions
3. **Create `image/plan.md`** â€” track generation progress

### Step 1: Generate Character Portraits (Priority 0)

**Before any scene keyframes**, generate character reference images. These are the visual anchors for the entire video â€” all subsequent frames reference them for consistency.

For each character in `script/characters/*.md`:

1. **Three-view sheet** â€” front / side (3/4) / back in one image:
   ```bash
   bash scripts/generate.sh \
     --prompt "Character turnaround sheet, three views (front, 3/4 side, back) of [character description from character sheet]. White background, full body, consistent lighting, reference sheet style" \
     --model "black-forest-labs/flux.2-pro" \
     --output image/characters/{name}-turnaround.png
   ```

2. **Individual portraits** (for frame-plan references):
   - Front portrait â†’ `image/characters/{name}-front.png`
   - Side (3/4) portrait â†’ `image/characters/{name}-side.png`
   - Back portrait â†’ `image/characters/{name}-back.png`

Use the turnaround sheet as reference for individual portraits to ensure consistency:
```bash
bash scripts/generate.sh \
  --prompt "Front portrait of [character description], head and shoulders, studio lighting" \
  --model "google/gemini-2.5-flash-image" \
  --reference image/characters/{name}-turnaround.png \
  --output image/characters/{name}-front.png
```

Save metadata to `image/log/character-{name}.json`.

### Step 2: Plan Scene Generation Queue

From `frame-plan.md`, build the ordered queue:

1. **Priority 1: Root cameras** â€” establishing shots (T2I, use character portraits + scene descriptions as reference)
2. **Priority 2: Child cameras** â€” medium/close shots derived from parent frames (I2I)
3. **Priority 3: Last frames** â€” for medium/large variation shots only

For each frame, note:
- Generation mode: T2I or I2I
- Model choice (user specifies or use default)
- Character portraits to reference (from Step 1)
- Target resolution

### Step 3: Generate Scene Keyframes

For each frame in the queue, call `scripts/generate.sh`:

```bash
# Root camera establishing shot (T2I, reference character portraits)
bash scripts/generate.sh \
  --prompt "Wide shot of a sunlit kitchen..." \
  --model "black-forest-labs/flux.2-pro" \
  --output image/frames/shot-01-ff.png

# Child camera (I2I, refine from parent frame)
bash scripts/generate.sh \
  --prompt "Medium shot, same kitchen, focus on woman at counter..." \
  --model "google/gemini-2.5-flash-image" \
  --reference image/frames/shot-01-ff.png \
  --output image/frames/shot-02-ff.png
```

After each generation:
- Verify image was saved successfully
- Log metadata to `image/log/shot-{NN}-ff.json` (model, cost, prompt, seed)
- Update `image/plan.md` with status

### Step 4: Quality Review

After all frames are generated:
1. Check character consistency â€” compare each frame's characters against turnaround sheet
2. Check scene consistency â€” same location should look the same across shots
3. Check visual continuity â€” parent/child camera shots should be spatially coherent
4. Flag any frames that need regeneration

### Step 5: Update Preview

Replace `[ğŸ–¼ï¸ å¾…ç”Ÿæˆ]` placeholders in `storyboard/storyboard-final/preview.md` with actual image paths.

> **Note:** This is a cross-directory write (image writing to storyboard's preview.md). This is an intentional exception to the "write only to own directory" rule â€” storyboard's Integration section acknowledges this update.

## Script Reference

### generate.sh

```bash
bash scripts/generate.sh [options]
```

| Argument | Description | Default |
|----------|-------------|---------|
| `--prompt`, `-p` | Image description | (required) |
| `--model`, `-m` | OpenRouter model ID | (required) |
| `--reference`, `-r` | Reference image path (for I2I / multi-modal) | â€” |
| `--output`, `-o` | Save image to this path | `./output.png` |
| `--modalities` | `image` (pure image models) or `image,text` (multi-modal) | auto-detect |
| `--size` | `square` / `portrait` / `landscape` | `landscape` |
| `--width` | Explicit width in pixels | â€” |
| `--height` | Explicit height in pixels | â€” |
| `--seed` | Reproducibility seed | â€” |

### Model ID examples (not exhaustive â€” models change frequently)

```bash
# Pure image models (modalities=image)
--model "black-forest-labs/flux.2-pro"
--model "black-forest-labs/flux.2-flex"

# Multi-modal models (modalities=image,text)
--model "google/gemini-2.5-flash-image"
--model "google/gemini-3-pro-image-preview"
--model "openai/gpt-5-image-mini"
```

> âš ï¸ Models and pricing change frequently. Do NOT hardcode model choices.
> Check https://openrouter.ai/models for current availability.

### Environment

The script reads `OPENROUTER_API_KEY` from environment or `.env` files. To set:

```bash
# Option 1: Environment variable
export OPENROUTER_API_KEY="sk-or-v1-..."

# Option 2: .env file (project root or ~/.env or ~/.aivp/.env)
echo "OPENROUTER_API_KEY=sk-or-v1-..." >> .env
```

## Project Output Structure

```
project/image/
â”œâ”€â”€ plan.md                    â† Track generation progress
â”œâ”€â”€ characters/                â† Character reference images (generated first)
â”‚   â”œâ”€â”€ elena-turnaround.png   â† Three-view sheet (front + side + back)
â”‚   â”œâ”€â”€ elena-front.png        â† Individual front portrait
â”‚   â”œâ”€â”€ elena-side.png         â† Individual 3/4 side portrait
â”‚   â”œâ”€â”€ elena-back.png         â† Individual back portrait
â”‚   â””â”€â”€ marco-turnaround.png
â”œâ”€â”€ frames/                    â† Scene keyframe images
â”‚   â”œâ”€â”€ shot-01-ff.png         â† Shot 1 first-frame
â”‚   â”œâ”€â”€ shot-01-lf.png         â† Shot 1 last-frame (if medium/large)
â”‚   â”œâ”€â”€ shot-02-ff.png
â”‚   â””â”€â”€ ...
â””â”€â”€ log/                       â† Generation metadata
    â”œâ”€â”€ character-elena.json   â† Character portrait generation log
    â”œâ”€â”€ shot-01-ff.json        â† Per-frame: model, cost, prompt, timestamp
    â””â”€â”€ ...
```

## References

- **OpenRouter Image API** â†’ `references/openrouter-image-api.md` â€” API format, modalities parameter, response parsing, base64 handling
- **Generation log template** â†’ `assets/generation-log-template.md` â€” Per-image metadata format

## Integration

- **Input from:** `aivp-storyboard` â†’
  - `storyboard/storyboard-final/frame-plan.md` â€” generation order + reference image list
  - `storyboard/storyboard-final/shots/*.md` â€” per-shot image prompts + resolution
  - `storyboard/storyboard-final/preview.md` â€” to update with generated image paths (cross-directory write)
- **Input from:** `aivp-script` â†’
  - `script/characters/*.md` â€” character visual descriptions (for generating turnaround sheets + portraits)
  - `script/scenes/*.md` â€” scene background descriptions
- **Output to:**
  - `aivp-video` â†’ `image/characters/*.png` (character portraits for reference) + `image/frames/*.png` (keyframes as video input)
  - `aivp-storyboard` â†’ updates `preview.md` image placeholders (cross-directory exception)

### Project Directory Convention

```
project/
â”œâ”€â”€ ideation/          â† aivp-ideation owns
â”œâ”€â”€ script/            â† aivp-script owns
â”œâ”€â”€ storyboard/        â† aivp-storyboard owns
â”œâ”€â”€ image/             â† aivp-image owns (this skill)
â”œâ”€â”€ video/             â† aivp-video (next)
â””â”€â”€ audio/             â† aivp-audio (next)
```

Each skill reads from upstream sibling directories and writes only to its own â€” except image updates storyboard's `preview.md` (acknowledged by both skills).

### Standalone Mode

When used outside the pipeline (no storyboard):

```bash
# Just generate an image
bash scripts/generate.sh \
  --prompt "A young woman in a red dress on a cliff, golden hour, cinematic" \
  --model "black-forest-labs/flux.2-pro" \
  --output my-image.png
```

The script works independently â€” no storyboard required.
